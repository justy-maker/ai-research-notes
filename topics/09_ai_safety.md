# 🛡️ AI 安全與對齊

> AI Safety & Alignment 研究

## 核心概念

### AI Safety（AI 安全）
確保 AI 系統不會造成意外傷害：
- 系統穩健性
- 可預測行為
- 失敗安全機制

### AI Alignment（AI 對齊）
確保 AI 的目標與人類價值觀一致：
- 價值對齊
- 意圖理解
- 長期目標一致性

## 研究方向

### 攻擊與防禦
- Prompt Injection 防護
- Jailbreaking 防禦
- Adversarial attacks

### 可靠性
- Hallucination 減少
- 事實查核
- 不確定性量化

### 倫理與公平
- 偏見檢測與修正
- 公平性評估
- 隱私保護

### 透明度
- 可解釋性 (Explainability)
- 決策追蹤
- 紅隊測試 (Red Teaming)

## 相關影片
*(待補充)*

## 研究筆記

---
*狀態：🟡 規劃中*
