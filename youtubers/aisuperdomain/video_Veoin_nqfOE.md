# 🚀 在 OpenClaw 中實測 Claude Opus 4.6 與 GPT-5.3-Codex！

- **頻道**: AI 超元域
- **日期**: 2026-02-12
- **連結**: https://www.youtube.com/watch?v=Veoin_nqfOE
- **標籤**: #ClaudeOpus #GPT5 #模型對比 #百萬Token

## 影片摘要

本期影片在 OpenClaw、Claude Code 和 Codex 中全面對比測試 Claude Opus 4.6 和 GPT-5.3-Codex 兩款最新模型，涵蓋知識庫、解碼、中文詩詞、推理、社群發帖、前端 UI、架構圖、動畫開發、Bug 排查、數學可視化等多項測試。

## 詳細測試結果

### 基本資訊
| 項目 | Claude Opus 4.6 | GPT-5.3 Codex |
|------|-----------------|---------------|
| 上下文窗口 | **100 萬 Token** | ~400K（推估） |
| 知識庫截止 | 2025 年初 | 2024 年 6 月 |
| Extended Thinking | ✅ 支援 | - |

### 測試 1：Base64 解碼
- **兩者都正確**解碼出 "All-in AI"
- GPT-5.3 回應速度明顯更快（幾乎秒回）

### 測試 2：中文詞牌（長相思）
- **兩者都正確**遵循長相思格律
- GPT-5.3 壓韻更自然
- Opus 4.6 有一句「性剪紅」稍顯拼湊，但整體不錯

### 測試 3：燈泡前綴編碼謎題
- **兩者都正確**：答案為最少需要 27 個燈泡
- Opus 4.6 給出更詳細的解題步驟

### 測試 4：農夫過河（加強版）
- **兩者都正確**，步驟完全一致
- GPT-5.3 響應速度更快
- Opus 4.6 回答質量更高：用表格展示每步左右岸狀態，加入 emoji，非常直觀

### 測試 5：社群發帖（X/Twitter）
- **Opus 4.6 勝出** ✅：成功發帖
- GPT-5.3 ❌ 拒絕執行，認為屬於「AI 自我保存」不適當行為，非常固執

### 測試 6：前端 UI 複刻
- **Opus 4.6 大勝** ✅：復刻精美，與原圖幾乎一模一樣，包含動態效果
- GPT-5.3 ❌：差距非常大，效果不佳

### 測試 7：SVG 架構圖（動態）
- **Opus 4.6 勝出** ✅：動畫效果佳、模組清晰
- GPT-5.3 ❌：畫面混亂、卡片配色與背景色相同

### 測試 8：冒泡排序動畫（Python + Pygame）
- **Opus 4.6 勝出** ✅：獅子形象逼真、非洲草原背景精美
- GPT-5.3：動畫可運行但獅子造型不如 Opus

### 測試 9：Bug 排查（叮叮插件）
- **兩者都找到了 Bug**：硬編碼 Agent ID 導致綁定失敗
- GPT-5.3 策略更聰明（直接從 GitHub 讀原碼），但 Opus 4.6 最終更快完成並給出修復代碼
- Opus 4.6 用全盤搜索方式，雖笨但速度更快

### 測試 10：數學函數可視化（Manim）
- **GPT-5.3 勝出** ✅：完美理解需求，生成二次函數動畫
- Opus 4.6 ❌：完全沒理解需求，一直安裝不必要的組件

## 總結

| 能力 | 優勝者 |
|------|--------|
| 響應速度 | GPT-5.3 Codex |
| 前端 UI | Claude Opus 4.6 |
| 視覺/動畫 | Claude Opus 4.6 |
| 指令遵循 | Claude Opus 4.6 |
| 複雜任務靈活性 | GPT-5.3 Codex |
| 回答質量/細節 | Claude Opus 4.6 |

**結論**：兩款模型各有優勢。Opus 4.6 更擅長前端、視覺、細節品質；GPT-5.3 在速度和複雜任務靈活性上更強。
